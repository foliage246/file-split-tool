from fastapi import APIRouter, UploadFile, File, HTTPException, Depends, BackgroundTasks, Form
from fastapi.responses import FileResponse
from typing import Optional
import os
import json
import uuid
from datetime import datetime

from ...core.config import settings
from ...core.redis_client import get_redis_client
from ...core.dependencies import get_current_user
from ...services.file_processor import FileProcessor
from ...utils.file_utils import is_supported_file_type, get_file_size_mb, validate_file_size
from ...models.task import TaskStatus, ProcessingTask
from ...models.user import User

router = APIRouter()


@router.post("/upload")
async def upload_file(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    column_name: str = Form(...),
    batch_size: Optional[int] = Form(None),
    user: User = Depends(get_current_user),
    redis_client = Depends(get_redis_client)
):
    """
    ä¸Šå‚³æª”æ¡ˆä¸¦é–‹å§‹è™•ç†
    
    Args:
        file: ä¸Šå‚³çš„æª”æ¡ˆ
        column_name: è¦åˆ‡åˆ†çš„æ¬„ä½åç¨±
        batch_size: æ¯å€‹æ‰¹æ¬¡çš„æœ€å¤§è¡Œæ•¸ï¼ˆå¯é¸ï¼‰
        user: ç•¶å‰ç”¨æˆ¶
    
    Returns:
        ä»»å‹™ ID å’Œåˆå§‹ç‹€æ…‹
    """
    try:
        # æª¢æŸ¥æª”æ¡ˆé¡å‹
        if not is_supported_file_type(file.filename):
            raise HTTPException(
                status_code=400,
                detail="ä¸æ”¯æ´çš„æª”æ¡ˆé¡å‹ã€‚æ”¯æ´æ ¼å¼: CSV, Excel (.xlsx, .xls), TXT"
            )
        
        # æª¢æŸ¥æª”æ¡ˆå¤§å°
        file_content = await file.read()
        file_size_mb = len(file_content) / (1024 * 1024)
        
        # æ ¹æ“šç”¨æˆ¶é¡å‹æª¢æŸ¥æª”æ¡ˆå¤§å°é™åˆ¶
        max_size = settings.PREMIUM_FILE_SIZE_LIMIT if user.is_premium else settings.FREE_FILE_SIZE_LIMIT
        if file_size_mb > max_size:
            raise HTTPException(
                status_code=413,
                detail=f"æª”æ¡ˆéå¤§ã€‚{'ä»˜è²»ç‰ˆ' if user.is_premium else 'å…è²»ç‰ˆ'}æœ€å¤§æ”¯æ´ {max_size}MB"
            )
        
        # æª¢æŸ¥æ¯æ—¥è™•ç†é™åˆ¶
        today = datetime.now().strftime("%Y-%m-%d")
        usage_key = f"daily_usage:{user.user_id}:{today}"
        current_usage = await redis_client.get(usage_key) or 0
        current_usage = int(current_usage)
        
        daily_limit = settings.PREMIUM_DAILY_LIMIT if user.is_premium else settings.FREE_DAILY_LIMIT
        if current_usage >= daily_limit:
            raise HTTPException(
                status_code=429,
                detail=f"å·²é”æ¯æ—¥è™•ç†é™åˆ¶ã€‚{'ä»˜è²»ç‰ˆ' if user.is_premium else 'å…è²»ç‰ˆ'}æ¯æ—¥å¯è™•ç† {daily_limit} å€‹æª”æ¡ˆ"
            )
        
        # é‡ç½®æª”æ¡ˆæŒ‡é‡
        await file.seek(0)
        
        # ç”Ÿæˆä»»å‹™ ID
        task_id = str(uuid.uuid4())
        
        # å‰µå»ºè™•ç†ä»»å‹™
        task = ProcessingTask(
            task_id=task_id,
            user_id=user.user_id,
            filename=file.filename,
            file_size_mb=round(file_size_mb, 2),
            column_name=column_name,
            status=TaskStatus.PENDING,
            created_at=datetime.now()
        )
        
        # å„²å­˜ä»»å‹™åˆ° Redis
        await redis_client.setex(
            f"task:{task_id}",
            3600,  # 1å°æ™‚éæœŸ
            json.dumps(task.dict(), default=str)
        )
        
        # æ›´æ–°æ¯æ—¥ä½¿ç”¨é‡
        await redis_client.incr(usage_key)
        await redis_client.expire(usage_key, 86400)  # 24å°æ™‚éæœŸ
        
        # å•Ÿå‹•èƒŒæ™¯è™•ç†
        background_tasks.add_task(process_file_background, task_id, file, column_name, batch_size)
        
        return {
            "task_id": task_id,
            "status": TaskStatus.PENDING,
            "message": "æª”æ¡ˆä¸Šå‚³æˆåŠŸï¼Œé–‹å§‹è™•ç†ä¸­..."
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æª”æ¡ˆä¸Šå‚³å¤±æ•—: {str(e)}")


@router.post("/split/{task_id}")
async def start_split_task(
    task_id: str,
    column_name: str,
    batch_size: Optional[int] = None,
    user: User = Depends(get_current_user),
    redis_client = Depends(get_redis_client)
):
    """
    æ‰‹å‹•å•Ÿå‹•æª”æ¡ˆåˆ‡åˆ†ä»»å‹™
    
    Args:
        task_id: ä»»å‹™ ID
        column_name: è¦åˆ‡åˆ†çš„æ¬„ä½åç¨±
        batch_size: æ¯å€‹æ‰¹æ¬¡çš„æœ€å¤§è¡Œæ•¸ï¼ˆå¯é¸ï¼‰
        user: ç•¶å‰ç”¨æˆ¶
    
    Returns:
        è™•ç†ç‹€æ…‹
    """
    try:
        # ç²å–ä»»å‹™è³‡è¨Š
        task_data = await redis_client.get(f"task:{task_id}")
        if not task_data:
            raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨æˆ–å·²éæœŸ")
        
        task_dict = json.loads(task_data)
        
        # æª¢æŸ¥ä»»å‹™æ“æœ‰è€…
        if task_dict.get("user_id") != user.user_id:
            raise HTTPException(status_code=403, detail="ç„¡æ¬Šè¨ªå•æ­¤ä»»å‹™")
        
        # æª¢æŸ¥ä»»å‹™ç‹€æ…‹
        if task_dict.get("status") != TaskStatus.UPLOADED:
            raise HTTPException(status_code=400, detail="ä»»å‹™ç‹€æ…‹ä¸æ­£ç¢ºï¼Œç„¡æ³•é–‹å§‹åˆ‡åˆ†")
        
        # æ›´æ–°ä»»å‹™ç‹€æ…‹
        task_dict["status"] = TaskStatus.PROCESSING
        task_dict["column_name"] = column_name
        task_dict["batch_size"] = batch_size
        task_dict["updated_at"] = datetime.now().isoformat()
        
        await redis_client.setex(
            f"task:{task_id}",
            3600,
            json.dumps(task_dict, default=str)
        )
        
        # å•Ÿå‹•èƒŒæ™¯è™•ç†ï¼ˆé€™è£¡æ‡‰è©²æœ‰å¯¦éš›çš„æª”æ¡ˆè™•ç†é‚è¼¯ï¼‰
        # background_tasks.add_task(process_split_background, task_id)
        
        return {
            "task_id": task_id,
            "status": TaskStatus.PROCESSING,
            "message": "åˆ‡åˆ†ä»»å‹™å·²å•Ÿå‹•"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å•Ÿå‹•åˆ‡åˆ†ä»»å‹™å¤±æ•—: {str(e)}")


@router.get("/status/{task_id}")
async def get_task_status(
    task_id: str,
    user: User = Depends(get_current_user),
    redis_client = Depends(get_redis_client)
):
    """
    æŸ¥è©¢ä»»å‹™è™•ç†ç‹€æ…‹
    
    Args:
        task_id: ä»»å‹™ ID
        user: ç•¶å‰ç”¨æˆ¶
    
    Returns:
        ä»»å‹™ç‹€æ…‹å’Œè™•ç†é€²åº¦
    """
    try:
        # ç²å–ä»»å‹™è³‡è¨Š
        task_data = await redis_client.get(f"task:{task_id}")
        if not task_data:
            raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨æˆ–å·²éæœŸ")
        
        task_dict = json.loads(task_data)
        
        # æª¢æŸ¥ä»»å‹™æ“æœ‰è€…
        if task_dict.get("user_id") != user.user_id:
            raise HTTPException(status_code=403, detail="ç„¡æ¬Šè¨ªå•æ­¤ä»»å‹™")
        
        # ç²å–è™•ç†çµæœï¼ˆå¦‚æœæœ‰ï¼‰
        result_data = await redis_client.get(f"result:{task_id}")
        result = json.loads(result_data) if result_data else None
        
        response = {
            "task_id": task_id,
            "status": task_dict.get("status"),
            "filename": task_dict.get("filename"),
            "file_size_mb": task_dict.get("file_size_mb"),
            "column_name": task_dict.get("column_name"),
            "batch_size": task_dict.get("batch_size"),
            "created_at": task_dict.get("created_at"),
            "updated_at": task_dict.get("updated_at"),
            "error_message": task_dict.get("error_message")
        }
        
        if result:
            response.update({
                "total_rows": result.get("total_rows"),
                "split_groups": result.get("split_groups"),
                "output_files": result.get("output_files"),
                "file_details": result.get("file_details")
            })
        
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è©¢ä»»å‹™ç‹€æ…‹å¤±æ•—: {str(e)}")


@router.get("/download/{task_id}")
async def download_result(
    task_id: str,
    user: User = Depends(get_current_user),
    redis_client = Depends(get_redis_client)
):
    """
    ä¸‹è¼‰è™•ç†çµæœ
    
    Args:
        task_id: ä»»å‹™ ID
        user: ç•¶å‰ç”¨æˆ¶
    
    Returns:
        è™•ç†çµæœæª”æ¡ˆ
    """
    try:
        # ç²å–ä»»å‹™è³‡è¨Š
        task_data = await redis_client.get(f"task:{task_id}")
        if not task_data:
            raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨æˆ–å·²éæœŸ")
        
        task_dict = json.loads(task_data)
        
        # æª¢æŸ¥ä»»å‹™æ“æœ‰è€…
        if task_dict.get("user_id") != user.user_id:
            raise HTTPException(status_code=403, detail="ç„¡æ¬Šè¨ªå•æ­¤ä»»å‹™")
        
        # æª¢æŸ¥ä»»å‹™æ˜¯å¦å®Œæˆ
        if task_dict.get("status") != TaskStatus.COMPLETED:
            raise HTTPException(status_code=400, detail="ä»»å‹™å°šæœªå®Œæˆï¼Œç„¡æ³•ä¸‹è¼‰")
        
        # ç²å–çµæœæª”æ¡ˆè·¯å¾‘
        result_data = await redis_client.get(f"result:{task_id}")
        if not result_data:
            raise HTTPException(status_code=404, detail="è™•ç†çµæœä¸å­˜åœ¨")
        
        result = json.loads(result_data)
        zip_path = result.get("zip_path")
        
        if not zip_path or not os.path.exists(zip_path):
            raise HTTPException(status_code=404, detail="çµæœæª”æ¡ˆä¸å­˜åœ¨")
        
        # è¿”å›æª”æ¡ˆ
        original_filename = task_dict.get("filename", "unknown")
        download_filename = f"{original_filename}_split_results.zip"
        
        return FileResponse(
            path=zip_path,
            filename=download_filename,
            media_type="application/zip"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¸‹è¼‰æª”æ¡ˆå¤±æ•—: {str(e)}")


async def process_file_background(
    task_id: str,
    file: UploadFile,
    column_name: str,
    batch_size: Optional[int] = None
):
    """
    èƒŒæ™¯è™•ç†æª”æ¡ˆåˆ‡åˆ†ä»»å‹™
    
    Args:
        task_id: ä»»å‹™ ID
        file: ä¸Šå‚³çš„æª”æ¡ˆ
        column_name: è¦åˆ‡åˆ†çš„æ¬„ä½åç¨±
        batch_size: æ¯å€‹æ‰¹æ¬¡çš„æœ€å¤§è¡Œæ•¸ï¼ˆå¯é¸ï¼‰
    """
    redis_client = get_redis_client()
    processor = FileProcessor()
    
    print(f"ğŸš€ é–‹å§‹è™•ç†ä»»å‹™: {task_id}, æª”æ¡ˆ: {file.filename}, æ¬„ä½: {column_name}")
    
    try:
        # æ›´æ–°ä»»å‹™ç‹€æ…‹ç‚ºè™•ç†ä¸­
        task_data = await redis_client.get(f"task:{task_id}")
        task_dict = json.loads(task_data)
        task_dict["status"] = TaskStatus.PROCESSING
        task_dict["updated_at"] = datetime.now().isoformat()
        
        await redis_client.setex(
            f"task:{task_id}",
            3600,
            json.dumps(task_dict, default=str)
        )
        
        # åŸ·è¡Œæª”æ¡ˆè™•ç†
        result = await processor.process_file(file, column_name, batch_size)
        
        if result["success"]:
            # æ›´æ–°ä»»å‹™ç‹€æ…‹ç‚ºå®Œæˆ
            task_dict["status"] = TaskStatus.COMPLETED
            task_dict["updated_at"] = datetime.now().isoformat()
            
            # å„²å­˜è™•ç†çµæœ
            await redis_client.setex(
                f"result:{task_id}",
                3600,
                json.dumps(result, default=str)
            )
        else:
            # è™•ç†å¤±æ•—
            print(f"âŒ è™•ç†å¤±æ•—: {result}")
            task_dict["status"] = TaskStatus.ERROR
            task_dict["error_message"] = result.get("error", "è™•ç†å¤±æ•—")
            task_dict["updated_at"] = datetime.now().isoformat()
        
        # æ›´æ–°ä»»å‹™ç‹€æ…‹
        await redis_client.setex(
            f"task:{task_id}",
            3600,
            json.dumps(task_dict, default=str)
        )
        
    except Exception as e:
        # è™•ç†ç•°å¸¸
        print(f"ğŸ’¥ èƒŒæ™¯ä»»å‹™ç•°å¸¸: {task_id}, éŒ¯èª¤: {str(e)}")
        
        try:
            task_data = await redis_client.get(f"task:{task_id}")
            if task_data:
                task_dict = json.loads(task_data)
                task_dict["status"] = TaskStatus.ERROR
                task_dict["error_message"] = str(e)
                task_dict["updated_at"] = datetime.now().isoformat()
                
                await redis_client.setex(
                    f"task:{task_id}",
                    3600,
                    json.dumps(task_dict, default=str)
                )
        except Exception as redis_error:
            print(f"ğŸ’¥ Redis æ›´æ–°éŒ¯èª¤: {str(redis_error)}")
    
    finally:
        # æ¸…ç†è³‡æº
        processor.cleanup()

